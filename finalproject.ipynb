{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as VIF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('music_features.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "label_mapping = dict(zip(label_encoder.transform(label_encoder.classes_), label_encoder.classes_))\n",
    "print(\"Label mapping:\", label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_standardize = [\n",
    "    'tempo', 'chroma_stft', 'rmse', 'spectral_centroid', \n",
    "    'spectral_bandwidth', 'rolloff', 'zero_crossing_rate'\n",
    "] + [f'mfcc{i}' for i in range(1, 21)]\n",
    "\n",
    "for feature in features_to_standardize:\n",
    "    df[feature] = (df[feature] - df[feature].mean()) / df[feature].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_corr = df.drop(columns=['filename', 'label', 'label_encoded'])\n",
    "\n",
    "corr_matrix = data_for_corr.corr()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Music Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. VIF calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vif = df.drop(columns=['filename', 'label', 'label_encoded'])\n",
    "# print(df_vif.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [VIF(df_vif, i)\n",
    "for i in range(0, df_vif.shape[1])]\n",
    "vif = pd.DataFrame({'vif':vals},\n",
    "index=df_vif.columns)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Previously Used models (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without 'beats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tempo', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff'] + \n",
    "       [f'mfcc{i}' for i in range(1, 21)]]\n",
    "y = df['label_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test_logistic = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "lm = LogisticRegression(class_weight='balanced', multi_class='multinomial', max_iter=1000)\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logistic = lm.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Results on Test Set\")\n",
    "p, r, f, s = precision_recall_fscore_support(y_test_logistic, y_pred_logistic, labels=np.unique(y))\n",
    "for label, genre in label_mapping.items():\n",
    "    print(f\"Genre: {genre}\")\n",
    "    print(f\"  Precision: {p[label]:.4f}\")\n",
    "    print(f\"  Recall: {r[label]:.4f}\")\n",
    "    print(f\"  F-score: {f[label]:.4f}\")\n",
    "    print(f\"  Support: {s[label]}\")\n",
    "\n",
    "target_names = ['Blues', 'Classical', 'Country', 'Disco', 'Hiphop', 'Jazz', \n",
    "                'Metal', 'Pop', 'Reggae', 'Rock']\n",
    "\n",
    "mat_logistic = confusion_matrix(y_test_logistic, y_pred_logistic)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(mat_logistic.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 'beats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tempo', 'beats', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff'] + \n",
    "       [f'mfcc{i}' for i in range(1, 21)]]\n",
    "y = df['label_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test_logistic = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "lm = LogisticRegression(class_weight='balanced', multi_class='multinomial', max_iter=1000)\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logistic = lm.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Results on Test Set\")\n",
    "p, r, f, s = precision_recall_fscore_support(y_test_logistic, y_pred_logistic, labels=np.unique(y))\n",
    "for label, genre in label_mapping.items():\n",
    "    print(f\"Genre: {genre}\")\n",
    "    print(f\"  Precision: {p[label]:.4f}\")\n",
    "    print(f\"  Recall: {r[label]:.4f}\")\n",
    "    print(f\"  F-score: {f[label]:.4f}\")\n",
    "    print(f\"  Support: {s[label]}\")\n",
    "\n",
    "target_names = ['Blues', 'Classical', 'Country', 'Disco', 'Hiphop', 'Jazz', \n",
    "                'Metal', 'Pop', 'Reggae', 'Rock']\n",
    "\n",
    "mat_logistic = confusion_matrix(y_test_logistic, y_pred_logistic)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(mat_logistic.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tempo', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff'] + \n",
    "       [f'mfcc{i}' for i in range(1, 21)]]\n",
    "y = df['label_encoded']\n",
    "\n",
    "lm = LogisticRegression(class_weight='balanced', multi_class='multinomial', max_iter=1000)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "coefficients = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    lm.fit(X_train, y_train)\n",
    "    \n",
    "    coefficients.append(lm.coef_)\n",
    "    \n",
    "    y_pred = lm.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, target_names=label_mapping.values()))\n",
    "\n",
    "\n",
    "coefficients = np.array(coefficients)\n",
    "avg_coefficients = np.mean(coefficients, axis=0)\n",
    "std_error_coefficients = np.std(coefficients, axis=0) / np.sqrt(cv.get_n_splits())\n",
    "\n",
    "coef_data = []\n",
    "for class_idx, class_name in label_mapping.items():\n",
    "    for feature_idx, feature_name in enumerate(X.columns):\n",
    "        coef_data.append({\n",
    "            'Class': class_name,\n",
    "            'Feature': feature_name,\n",
    "            'Average Coefficient': avg_coefficients[class_idx, feature_idx],\n",
    "            'Standard Error': std_error_coefficients[class_idx, feature_idx]\n",
    "        })\n",
    "\n",
    "coef_df = pd.DataFrame(coef_data)\n",
    "print(coef_df)\n",
    "\n",
    "class_averages = coef_df.groupby('Class').agg(\n",
    "    Average_Coefficient=('Average Coefficient', 'mean'),\n",
    "    Average_Standard_Error=('Standard Error', 'mean')\n",
    ").reset_index()\n",
    "print(class_averages)\n",
    "\n",
    "class_name_to_visualize = \"rock\"  # Change to any class you want to visualize\n",
    "class_df = coef_df[coef_df['Class'] == class_name_to_visualize].sort_values(\n",
    "    by='Average Coefficient', key=abs, ascending=False\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(class_df['Feature'], class_df['Average Coefficient'], xerr=class_df['Standard Error'])\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.title(f'Average Coefficients with Standard Errors for Class: {class_name_to_visualize}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Fit logistic regression on full dataset to rank features\n",
    "lm_full = LogisticRegression(class_weight='balanced', multi_class='multinomial', max_iter=1000)\n",
    "lm_full.fit(X, y)\n",
    "\n",
    "# Rank features by absolute coefficient values\n",
    "coef_magnitudes = np.abs(lm_full.coef_).mean(axis=0)\n",
    "top_features = np.argsort(coef_magnitudes)[-10:]  # Select top 10 variables\n",
    "top_features_names = X.columns[top_features]\n",
    "\n",
    "# Refit logistic regression using only top-N features\n",
    "X_top = X[top_features_names]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "lm_top = LogisticRegression(class_weight='balanced', multi_class='multinomial', max_iter=1000)\n",
    "lm_top.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = lm_top.predict(X_test)\n",
    "print(\"Logistic Model with Top-N Variables\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_mapping.values()))\n",
    "print(\"Top Features:\", top_features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as VIF\n",
    "\n",
    "# Calculate VIF\n",
    "X_vif = X.copy()\n",
    "vif_data = pd.DataFrame({\n",
    "    'Feature': X_vif.columns,\n",
    "    'VIF': [VIF(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
    "})\n",
    "\n",
    "# Filter features with VIF < 5\n",
    "low_vif_features = vif_data[vif_data['VIF'] < 5]['Feature']\n",
    "X_low_vif = X[low_vif_features]\n",
    "\n",
    "# Refit logistic regression using low VIF variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_low_vif, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "lm_vif = LogisticRegression(class_weight='balanced', multi_class='multinomial', max_iter=1000)\n",
    "lm_vif.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = lm_vif.predict(X_test)\n",
    "print(\"Logistic Model with Low-VIF Variables\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_mapping.values()))\n",
    "print(\"Low VIF Features:\", low_vif_features.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Backward selection function with correction\n",
    "def backward_selection(X, y, significance_level=0.05):\n",
    "    # Add intercept term\n",
    "    X_with_const = sm.add_constant(X)\n",
    "    model = sm.MNLogit(y, X_with_const).fit()\n",
    "\n",
    "    while True:\n",
    "        # Get p-values for all features except the intercept\n",
    "        pvalues = model.pvalues.iloc[1:]  # Exclude the constant term\n",
    "        max_pvalue = pvalues.max().max()  # Max across features and classes\n",
    "\n",
    "        if max_pvalue > significance_level:\n",
    "            # Find the feature corresponding to the max p-value\n",
    "            excluded_feature = pvalues.max(axis=1).idxmax()\n",
    "            X_with_const = X_with_const.drop(columns=[excluded_feature])  # Drop the feature\n",
    "            model = sm.MNLogit(y, X_with_const).fit()  # Refit the model\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return model, X_with_const.columns  # Return the final model and selected features\n",
    "\n",
    "# Perform backward selection\n",
    "model, selected_features = backward_selection(X, y)\n",
    "print(\"Selected Features from Backward Selection:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# PCR Pipeline\n",
    "pca = PCA(n_components=10)\n",
    "lm_pca = LogisticRegression(class_weight='balanced', multi_class='multinomial', max_iter=1000)\n",
    "pcr_pipeline = Pipeline([('pca', pca), ('logistic', lm_pca)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "pcr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pcr_pipeline.predict(X_test)\n",
    "print(\"Logistic Model with Principal Components\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_mapping.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data preparation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Regularization parameters\n",
    "alpha = 1.0  # Regularization strength\n",
    "\n",
    "# Ridge (L2 Regularization)\n",
    "ridge_model = LogisticRegression(\n",
    "    penalty='l2', solver='saga', multi_class='multinomial', C=1/alpha, max_iter=1000\n",
    ")\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_predictions = ridge_model.predict(X_test)\n",
    "\n",
    "print(\"Ridge Logistic Regression\")\n",
    "print(classification_report(y_test, ridge_predictions, target_names=label_mapping.values()))\n",
    "\n",
    "# LASSO (L1 Regularization)\n",
    "lasso_model = LogisticRegression(\n",
    "    penalty='l1', solver='saga', multi_class='multinomial', C=1/alpha, max_iter=1000\n",
    ")\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_predictions = lasso_model.predict(X_test)\n",
    "\n",
    "print(\"LASSO Logistic Regression\")\n",
    "print(classification_report(y_test, lasso_predictions, target_names=label_mapping.values()))\n",
    "\n",
    "# Elastic Net (Combination of L1 and L2)\n",
    "elastic_net_model = LogisticRegression(\n",
    "    penalty='elasticnet', solver='saga', multi_class='multinomial', C=1/alpha, l1_ratio=0.5, max_iter=1000\n",
    ")\n",
    "elastic_net_model.fit(X_train, y_train)\n",
    "elastic_net_predictions = elastic_net_model.predict(X_test)\n",
    "\n",
    "print(\"Elastic Net Logistic Regression\")\n",
    "print(classification_report(y_test, elastic_net_predictions, target_names=label_mapping.values()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is something wrong with Ridge regression, I still need to fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.linear_model import ElasticNetCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import cross_validate, KFold\n",
    "\n",
    "# # Data preparation\n",
    "# X_standardized = (X - X.mean(axis=0)) / X.std(axis=0)  # Standardize features\n",
    "# lambdas = 10**np.linspace(8, -2, 100)  # Define lambda (alpha) values\n",
    "\n",
    "# # Ridge regression using ElasticNetCV with l1_ratio=0\n",
    "# ridge_cv = ElasticNetCV(alphas=lambdas, l1_ratio=0, cv=5, max_iter=100000)\n",
    "\n",
    "# # Create a pipeline with standardization and ridge regression\n",
    "# ridge_pipeline = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('ridge', ridge_cv)\n",
    "# ])\n",
    "\n",
    "# # Fit the model\n",
    "# ridge_pipeline.fit(X, y)\n",
    "\n",
    "# # Extract best alpha (lambda) and coefficients\n",
    "# best_lambda = ridge_cv.alpha_\n",
    "# ridge_coefficients = ridge_cv.coef_\n",
    "\n",
    "# print(\"Best Lambda (Ridge):\", best_lambda)\n",
    "# print(\"Ridge Coefficients:\", ridge_coefficients)\n",
    "\n",
    "# # Cross-validated MSE\n",
    "# cv_results = cross_validate(ridge_pipeline, X, y, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "# cv_mse = -np.mean(cv_results['test_score'])\n",
    "\n",
    "# print(\"Cross-Validated MSE (Ridge):\", cv_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare LASSO Regression\n",
    "lasso_cv = ElasticNetCV(l1_ratio=1, n_alphas=100, cv=5, max_iter=10000)\n",
    "\n",
    "# Create a pipeline for standardization and LASSO\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', lasso_cv)\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "lasso_pipeline.fit(X, y)\n",
    "\n",
    "# Extract the tuned LASSO model\n",
    "tuned_lasso = lasso_pipeline.named_steps['lasso']\n",
    "\n",
    "# Best alpha (lambda) value\n",
    "best_lambda = tuned_lasso.alpha_\n",
    "print(\"Best Lambda (LASSO):\", best_lambda)\n",
    "\n",
    "# Cross-validated MSE\n",
    "cv_results = cross_validate(lasso_pipeline, X, y, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "cv_mse = -np.mean(cv_results['test_score'])\n",
    "print(\"Cross-Validated MSE (LASSO):\", cv_mse)\n",
    "\n",
    "# Extract coefficients\n",
    "lasso_coefficients = tuned_lasso.coef_\n",
    "print(\"LASSO Coefficients:\", lasso_coefficients)\n",
    "\n",
    "# Number of non-zero coefficients\n",
    "non_zero_coefficients = np.sum(lasso_coefficients != 0)\n",
    "print(\"Number of Non-Zero Coefficients:\", non_zero_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import lasso_path\n",
    "\n",
    "# Compute LASSO path\n",
    "alphas, coefs, _ = lasso_path(X, y)\n",
    "\n",
    "# Plot the coefficient paths\n",
    "plt.figure(figsize=(8, 6))\n",
    "for coef in coefs:\n",
    "    plt.plot(-np.log10(alphas), coef)\n",
    "plt.xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "plt.ylabel('Coefficients', fontsize=20)\n",
    "plt.title('LASSO Coefficient Paths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cross-validated MSE\n",
    "plt.figure(figsize=(8, 6))\n",
    "mean_mse = tuned_lasso.mse_path_.mean(axis=1)\n",
    "std_mse = tuned_lasso.mse_path_.std(axis=1)\n",
    "\n",
    "plt.errorbar(-np.log10(tuned_lasso.alphas_), mean_mse, yerr=std_mse / np.sqrt(5))\n",
    "plt.axvline(-np.log10(tuned_lasso.alpha_), color='k', linestyle='--')\n",
    "plt.xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "plt.ylabel('Cross-validated MSE', fontsize=20)\n",
    "plt.title('LASSO Cross-Validation Error')\n",
    "plt.ylim([50000, 250000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
