{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeClassifierCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as VIF\n",
    "import statsmodels.api as sm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('music_features.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "label_mapping = dict(zip(label_encoder.transform(label_encoder.classes_), label_encoder.classes_))\n",
    "print(\"Label mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_standardize = [\n",
    "    'tempo', 'chroma_stft', 'rmse', 'spectral_centroid', \n",
    "    'spectral_bandwidth', 'rolloff', 'zero_crossing_rate'\n",
    "] + [f'mfcc{i}' for i in range(1, 21)]\n",
    "\n",
    "for feature in features_to_standardize:\n",
    "    df[feature] = (df[feature] - df[feature].mean()) / df[feature].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_corr = df.drop(columns=['filename', 'label', 'label_encoded'])\n",
    "\n",
    "corr_matrix = data_for_corr.corr()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Music Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. VIF calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vif = df.drop(columns=['filename', 'label', 'label_encoded'])\n",
    "# print(df_vif.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [VIF(df_vif, i)\n",
    "for i in range(0, df_vif.shape[1])]\n",
    "vif = pd.DataFrame({'vif':vals},\n",
    "index=df_vif.columns)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Previously Used models (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without 'beats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tempo', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff'] + \n",
    "       [f'mfcc{i}' for i in range(1, 21)]]\n",
    "y = df['label_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test_logistic = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "lm = LogisticRegression(class_weight='balanced', multi_class='multinomial', max_iter=1000)\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logistic = lm.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Results on Test Set\")\n",
    "p, r, f, s = precision_recall_fscore_support(y_test_logistic, y_pred_logistic, labels=np.unique(y))\n",
    "for label, genre in label_mapping.items():\n",
    "    print(f\"Genre: {genre}\")\n",
    "    print(f\"  Precision: {p[label]:.4f}\")\n",
    "    print(f\"  Recall: {r[label]:.4f}\")\n",
    "    print(f\"  F-score: {f[label]:.4f}\")\n",
    "    print(f\"  Support: {s[label]}\")\n",
    "\n",
    "target_names = ['Blues', 'Classical', 'Country', 'Disco', 'Hiphop', 'Jazz', \n",
    "                'Metal', 'Pop', 'Reggae', 'Rock']\n",
    "\n",
    "mat_logistic = confusion_matrix(y_test_logistic, y_pred_logistic)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(mat_logistic.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 'beats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tempo', 'beats', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff'] + \n",
    "       [f'mfcc{i}' for i in range(1, 21)]]\n",
    "y = df['label_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test_logistic = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "lm = LogisticRegression(class_weight='balanced', multi_class='multinomial', max_iter=1000)\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logistic = lm.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Results on Test Set\")\n",
    "p, r, f, s = precision_recall_fscore_support(y_test_logistic, y_pred_logistic, labels=np.unique(y))\n",
    "for label, genre in label_mapping.items():\n",
    "    print(f\"Genre: {genre}\")\n",
    "    print(f\"  Precision: {p[label]:.4f}\")\n",
    "    print(f\"  Recall: {r[label]:.4f}\")\n",
    "    print(f\"  F-score: {f[label]:.4f}\")\n",
    "    print(f\"  Support: {s[label]}\")\n",
    "\n",
    "target_names = ['Blues', 'Classical', 'Country', 'Disco', 'Hiphop', 'Jazz', \n",
    "                'Metal', 'Pop', 'Reggae', 'Rock']\n",
    "\n",
    "mat_logistic = confusion_matrix(y_test_logistic, y_pred_logistic)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(mat_logistic.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tempo', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff'] + \n",
    "       [f'mfcc{i}' for i in range(1, 21)]]\n",
    "y = df['label_encoded']\n",
    "\n",
    "lm = LogisticRegression(class_weight='balanced', multi_class='multinomial', max_iter=1000)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "coefficients = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    lm.fit(X_train, y_train)\n",
    "    \n",
    "    coefficients.append(lm.coef_)\n",
    "    \n",
    "    y_pred = lm.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, target_names=label_mapping.values()))\n",
    "\n",
    "\n",
    "coefficients = np.array(coefficients)\n",
    "avg_coefficients = np.mean(coefficients, axis=0)\n",
    "std_error_coefficients = np.std(coefficients, axis=0) / np.sqrt(cv.get_n_splits())\n",
    "\n",
    "coef_data = []\n",
    "for class_idx, class_name in label_mapping.items():\n",
    "    for feature_idx, feature_name in enumerate(X.columns):\n",
    "        coef_data.append({\n",
    "            'Class': class_name,\n",
    "            'Feature': feature_name,\n",
    "            'Average Coefficient': avg_coefficients[class_idx, feature_idx],\n",
    "            'Standard Error': std_error_coefficients[class_idx, feature_idx]\n",
    "        })\n",
    "\n",
    "coef_df = pd.DataFrame(coef_data)\n",
    "print(coef_df)\n",
    "\n",
    "class_averages = coef_df.groupby('Class').agg(\n",
    "    Average_Coefficient=('Average Coefficient', 'mean'),\n",
    "    Average_Standard_Error=('Standard Error', 'mean')\n",
    ").reset_index()\n",
    "print(class_averages)\n",
    "\n",
    "class_name_to_visualize = \"rock\"  # Change to any class you want to visualize\n",
    "class_df = coef_df[coef_df['Class'] == class_name_to_visualize].sort_values(\n",
    "    by='Average Coefficient', key=abs, ascending=False\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(class_df['Feature'], class_df['Average Coefficient'], xerr=class_df['Standard Error'])\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.title(f'Average Coefficients with Standard Errors for Class: {class_name_to_visualize}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_full = LogisticRegression(class_weight='balanced', multi_class='multinomial', max_iter=1000)\n",
    "lm_full.fit(X, y)\n",
    "\n",
    "coef_magnitudes = np.abs(lm_full.coef_).mean(axis=0)\n",
    "top_features = np.argsort(coef_magnitudes)[-10:]\n",
    "top_features_names = X.columns[top_features]\n",
    "\n",
    "X_top = X[top_features_names]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "lm_top = LogisticRegression(class_weight='balanced', multi_class='multinomial', max_iter=1000)\n",
    "lm_top.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lm_top.predict(X_test)\n",
    "print(\"Logistic Model with Top-N Variables\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_mapping.values()))\n",
    "print(\"Top Features:\", top_features_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vif = X.copy()\n",
    "vif_data = pd.DataFrame({\n",
    "    'Feature': X_vif.columns,\n",
    "    'VIF': [VIF(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
    "})\n",
    "\n",
    "low_vif_features = vif_data[vif_data['VIF'] < 5]['Feature']\n",
    "X_low_vif = X[low_vif_features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_low_vif, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "lm_vif = LogisticRegression(class_weight='balanced', multi_class='multinomial', max_iter=1000)\n",
    "lm_vif.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lm_vif.predict(X_test)\n",
    "print(\"Logistic Model with Low-VIF Variables\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_mapping.values()))\n",
    "print(\"Low VIF Features:\", low_vif_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_selection(X, y, significance_level=1):\n",
    "    X_with_const = sm.add_constant(X)\n",
    "    \n",
    "    model = sm.MNLogit(y, X_with_const).fit()\n",
    "    \n",
    "    while True:\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        max_pvalue = pvalues.max().max()\n",
    "        \n",
    "        if max_pvalue > significance_level:\n",
    "            excluded_feature = pvalues.max(axis=1).idxmax()\n",
    "            X_with_const = X_with_const.drop(columns=[excluded_feature]) \n",
    "            model = sm.MNLogit(y, X_with_const).fit()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return model, X_with_const.columns\n",
    "\n",
    "model, selected_features = backward_selection(X, y)\n",
    "print(\"Selected Features from Backward Selection:\", selected_features)\n",
    "\n",
    "X_selected = X[selected_features.drop(\"const\")]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "log_reg = sm.MNLogit(y_train, sm.add_constant(X_train)).fit()\n",
    "\n",
    "y_pred_prob = log_reg.predict(sm.add_constant(X_test))\n",
    "y_pred_class = np.argmax(y_pred_prob.values, axis=1)\n",
    "\n",
    "unique_labels = sorted(np.unique(y))\n",
    "target_names = [label_mapping[label] for label in unique_labels]\n",
    "\n",
    "print(\"Backward Selection Classification Metrics\")\n",
    "print(classification_report(y_test, y_pred_class, target_names=target_names, labels=unique_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "lm_pca = LogisticRegression(class_weight='balanced', multi_class='multinomial', max_iter=1000)\n",
    "pcr_pipeline = Pipeline([('pca', pca), ('logistic', lm_pca)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "pcr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pcr_pipeline.predict(X_test)\n",
    "print(\"Logistic Model with Principal Components\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_mapping.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "lambdas = 10**np.linspace(4, -2, 50)\n",
    "\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', RidgeClassifierCV(alphas=lambdas, cv=5))\n",
    "])\n",
    "\n",
    "ridge_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class = ridge_pipeline.predict(X_test)\n",
    "\n",
    "unique_labels = sorted(np.unique(y_test))\n",
    "target_names = [label_mapping[label] for label in unique_labels]\n",
    "\n",
    "print(\"Ridge Classifier Classification Metrics\")\n",
    "print(classification_report(y_test, y_pred_class, target_names=target_names))\n",
    "\n",
    "mat_logistic = confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(mat_logistic.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "plt.title('Confusion Matrix - Ridge Regularization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "lasso_classifier_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(\n",
    "        penalty='l1',\n",
    "        solver='saga',\n",
    "        max_iter=10000,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        multi_class='multinomial',\n",
    "        n_jobs=-1 \n",
    "    ))\n",
    "])\n",
    "\n",
    "C_values = np.logspace(-4, 4, 50)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lasso_classifier_pipeline,\n",
    "    param_distributions={'logreg__C': C_values},\n",
    "    n_iter=20,\n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1 \n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "y_pred_class = best_model.predict(X_test)\n",
    "\n",
    "unique_labels = sorted(np.unique(y_test))\n",
    "target_names = [label_mapping[label] for label in unique_labels]\n",
    "\n",
    "print(\"Lasso Classifier Metrics\")\n",
    "print(classification_report(y_test, y_pred_class, target_names=target_names))\n",
    "\n",
    "coefficients = list(zip(best_model.named_steps['logreg'].coef_.T, X.columns))\n",
    "non_zero_coefficients = [coef for coef in coefficients if np.any(coef[0] != 0)]\n",
    "\n",
    "print(\"Non-zero Coefficients:\")\n",
    "for coef, name in non_zero_coefficients:\n",
    "    print(f\"{name}: {coef}\")\n",
    "\n",
    "mat_logistic = confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(mat_logistic.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "plt.title('Confusion Matrix - Lasso Regularization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "elastic_net_classifier = LogisticRegressionCV(\n",
    "    penalty='elasticnet',\n",
    "    solver='saga',\n",
    "    max_iter=10000,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    cv=5,\n",
    "    l1_ratios=np.linspace(0.1, 1.0, 10),\n",
    "    n_jobs=-1 \n",
    ")\n",
    "\n",
    "elastic_net_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_class = elastic_net_classifier.predict(X_test_scaled)\n",
    "unique_labels = sorted(np.unique(y_test))\n",
    "target_names = [label_mapping[label] for label in unique_labels]\n",
    "\n",
    "print(\"Elastic Net Classification Metrics\")\n",
    "print(classification_report(y_test, y_pred_class, target_names=target_names))\n",
    "\n",
    "\n",
    "coefficients = list(zip(elastic_net_classifier.coef_.T, X.columns))\n",
    "non_zero_coefficients = [coef for coef in coefficients if np.any(coef[0] != 0)]\n",
    "\n",
    "print(\"Non-zero Coefficients:\")\n",
    "for coef, name in non_zero_coefficients:\n",
    "    print(f\"{name}: {coef}\")\n",
    "\n",
    "mat_logistic = confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(mat_logistic.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "plt.title('Confusion Matrix - Elastic Net Regularization')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
